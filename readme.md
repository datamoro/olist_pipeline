# ğŸ“˜ Olist E-commerce Analytics â€“ Data Pipeline with PostgreSQL, Docker & Superset

## ğŸ“– Project Overview
This project implements an **end-to-end data pipeline** for the [Olist Brazilian E-commerce dataset](https://www.kaggle.com/datasets/olistbr/brazilian-ecommerce).  


It demonstrates:
- **Data ingestion** into PostgreSQL
- **Cleaning & transformation** with Python (pandas + SQLAlchemy)
- **Dimensional modeling** with SQL views
- **Interactive BI dashboards** in Apache Superset
- **Containerized orchestration** with Docker

---

## âš™ï¸ Architecture

(Architecture diagram in text)

                 +-------------------+
                 |   Kaggle Dataset  |
                 |   (CSV files)     |
                 +---------+---------+
                           |
                           v
                 +-------------------+
                 |  Python (pandas)  |
                 |  load_data.py     |
                 |  - cleaning       |
                 |  - deduplication  |
                 |  - type casting   |
                 +---------+---------+
                           |
                           v
                 +-------------------+
                 | PostgreSQL (raw)  |
                 +---------+---------+
                           |
                           v
                 +-------------------+
                 | PostgreSQL (views)|
                 |  analytics schema |
                 |  - facts          |
                 |  - dimensions     |
                 +---------+---------+
                           |
                           v
                 +-------------------+
                 | Apache Superset   |
                 | - Datasets        |
                 | - Filters         |
                 | - Dashboards      |
                 +-------------------+

---

## ğŸ› ï¸ Tech Stack
- **PostgreSQL 15** â€“ relational database & SQL views  
- **Docker & docker-compose** â€“ container orchestration  
- **Python 3.10 + pandas + SQLAlchemy** â€“ ETL and cleaning  
- **Apache Superset** â€“ dashboarding and BI  

---

## ğŸ“‚ Repository Structure

~~~text
olist_pipeline/
â”‚
â”œâ”€â”€ data/                   # Raw CSVs from Kaggle
â”œâ”€â”€ etl/
â”‚   â”œâ”€â”€ load_data.py        # ETL script with cleaning
â”‚   â””â”€â”€ requirements.txt    # Python dependencies
â”‚
â”œâ”€â”€ sql/
â”‚   â””â”€â”€ 00_create_schemas.sql
â”‚   â””â”€â”€ 01_dim_customers.sql
â”‚   â””â”€â”€ 02_dim_sellers.sql
â”‚   â””â”€â”€ 03_dim_products.sql
â”‚   â””â”€â”€ 04_dim_date.sql
â”‚   â””â”€â”€ 10_vw_payments_agg.sql
â”‚   â””â”€â”€ 11_vw_reviews_latest.sql
â”‚   â””â”€â”€ 12_vw_fct_order_items.sql
â”‚   â””â”€â”€ 13_vw_fct_orders.sql
â”‚   â””â”€â”€ 20_vw_monthly_sales.sql
â”‚   â””â”€â”€ 21_vw_category_sales.sql
â”‚   â””â”€â”€ 22_vw_delivery_performance.sql
â”‚
â”œâ”€â”€ superset/
â”‚   â”œâ”€â”€ docker-init.sh      # Init script for Superset
â”‚   â””â”€â”€ superset_config.py  # Superset config
â”‚
â”œâ”€â”€ docker-compose.yml      # Services (Postgres, Superset)
â””â”€â”€ README.md               # Documentation
~~~

---

## ğŸš€ Setup & Execution

### 1) Clone the repo
~~~bash
git clone https://github.com/<your-username>/olist-pipeline.git
cd olist-pipeline
~~~

### 2) Start containers
~~~bash
docker-compose up --build
~~~
- PostgreSQL â†’ `localhost:5432`  
- Superset â†’ `http://localhost:8088`

### 3) Load the data
From the `etl/` folder:

~~~bash
python3 -m venv .venv
source .venv/bin/activate
pip install -r requirements.txt

python load_data.py \
  --user <db_user> \
  --password <db_password> \
  --host <db_host> \
  --port <db_port> \
  --database <db_name> \
  --schema raw \
  --data-path ../data/
~~~

> â„¹ï¸ Connection args can also come from environment variables (e.g., a `.env` file).

### 4) Create analytics views
Run your SQL scripts (e.g., `vw_fct_orders.sql`, `vw_fct_order_items.sql`, `dim_customers.sql`) in the `analytics` schema using DBeaver or `psql`.

### 5) Connect Superset
- Open `http://localhost:8088`  
- Add DB connection:  
  `postgresql://<db_user>:<db_password>@olist_postgres:5432/olist_db`  
- Register datasets from schema **analytics**  
- Build charts and dashboards  

---

## ğŸ§¼ Data Cleaning Rules
The ETL applies:
1. Remove duplicates  
2. Replace `"nan"` strings with NULL  
3. Cast `timestamp`/`date` columns â†’ proper datetime  
4. Format `zip_code` columns as 8-character strings (leading zeros)

---

## ğŸ“ Data Modeling

We use a **star schema** with denormalized facts for BI.

### Fact views
- **`analytics.vw_fct_order_items`** â€“ item-level fact joining orders, products (with category translation), sellers, customers, payments (aggregated), and latest review. Includes derived fields like `delivery_days`, and filter-friendly columns such as:
  - `iso_state` = `'BR-' || customer_state`
  - `category_display` = `COALESCE(product_category_name_english, product_category_name)`
- **`analytics.vw_fct_orders`** â€“ order-level fact aggregating items and payments; includes `delivery_days`.

### Dimension views
- `analytics.dim_customers`
- `analytics.dim_sellers`
- `analytics.dim_products` (with English categories)
- `analytics.dim_date`

### Helper views
- `analytics.vw_payments_agg` â€“ payments aggregated at order level
- `analytics.vw_reviews_latest` â€“ latest review per order

---

## ğŸ“Š Dashboard Features

**Global filters**
- Date (`order_purchase_timestamp`)  
- State (`iso_state`)  
- Product category (`category_display`)  

**Example charts**
- Monthly revenue trend (line)  
- Revenue by category (bar)  
- Orders by state (map)  
- Delivery days distribution (histogram, bin size 5, filter `delivery_days <= 60`)  
- Seller leaderboard (table)  
- Payment method mix (pie/bar)  
- Review score distribution (hist/box)

**KPIs**
- Total revenue = `SUM(total_payment_value)`  
- Orders = `COUNT DISTINCT order_id`  
- Avg delivery days = `AVG(delivery_days)`  
- Avg review score = `AVG(review_score)`

---

## ğŸ“ˆ Example Insights (v1)
- Most deliveries take **7â€“15 days**; long tail > **30 days**  
- **SP** leads revenue and order volume  
- Top categories include **Health & Beauty**, **Bed & Bath**, **Computers/Accessories**  
- **Credit card** dominates payments  

---

## ğŸ—“ï¸ Roadmap
- Materialized views for heavy queries  
- Orchestration (Airflow/Prefect)  
- dbt for SQL transformation versioning  
- New analyses: retention, repeat purchases, cohort charts

---

## ğŸ“œ License
MIT License.
